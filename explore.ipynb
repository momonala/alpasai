{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634582d0-c7b2-4249-811f-6bd87553c151",
   "metadata": {},
   "source": [
    "## Workflow:\n",
    "\n",
    "1. Read in data\n",
    "2. Preprocess data (lowercase, special chars, extra spaces)\n",
    "3. Inspect data:\n",
    "   - missing values\n",
    "   - duplicate values\n",
    "   - tag distribution\n",
    "   - sameness of entities 1 and 2 (size, token length)\n",
    "4. Preprocessing data\n",
    "5. Setup Baseline model\n",
    "   - feature extraction\n",
    "   - modelling\n",
    "6. Training and evaluation\n",
    "   - Split data into training, validation, and test sets.\n",
    "   - Cross validation\n",
    "   - ROC-AUC, precision, recall, and F1-score. (Focus on recall so QA flags as many true negatives as possible).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "384afc60-ac05-4789-986b-c52b28be57ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7042846, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity_1</th>\n",
       "      <th>entity_2</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3137667</td>\n",
       "      <td>preciform A.B</td>\n",
       "      <td>Preciform AB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5515816</td>\n",
       "      <td>degener staplertechnik vertriebs-gmbh</td>\n",
       "      <td>Irshim</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215797</td>\n",
       "      <td>Alltel South CaroliNA Inc</td>\n",
       "      <td>alltel south carolina INC.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004621</td>\n",
       "      <td>cse Corporation</td>\n",
       "      <td>Cse Corp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1698689</td>\n",
       "      <td>Gruppo D Motors Srl</td>\n",
       "      <td>gruppo d motors Sociedad de Resposabilidad Lim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                               entity_1  \\\n",
       "0  3137667                          preciform A.B   \n",
       "1  5515816  degener staplertechnik vertriebs-gmbh   \n",
       "2   215797              Alltel South CaroliNA Inc   \n",
       "3  1004621                        cse Corporation   \n",
       "4  1698689                    Gruppo D Motors Srl   \n",
       "\n",
       "                                            entity_2  tag  \n",
       "0                                       Preciform AB    1  \n",
       "1                                             Irshim    0  \n",
       "2                         alltel south carolina INC.    1  \n",
       "3                                           Cse Corp    1  \n",
       "4  gruppo d motors Sociedad de Resposabilidad Lim...    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/ds_challenge_alpas.csv')\n",
    "df.columns = ['id', 'entity_1', 'entity_2', 'tag']\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e3fce-a89b-4e91-b936-b0503df8477e",
   "metadata": {},
   "source": [
    "✅ We are working on a binary classifcation task with already labeled data. \n",
    "\n",
    "✅ 7,042,846 examples\n",
    "\n",
    "This number of samples is quite high (300MB) and may raise some problems when it comes to RAM and fitting times on a local setup. So we just take a slice of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318b41a1-9293-476d-b761-56e3b2530ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70428, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=.01, random_state=123).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69956a40-d19e-4a78-b8c2-653f5ea9bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "id          0\n",
      "entity_1    0\n",
      "entity_2    0\n",
      "tag         0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "Distribution of binary tag:\n",
      " tag\n",
      "0    0.591654\n",
      "1    0.408346\n",
      "Name: proportion, dtype: float64\n",
      "Basic statistics for entity lengths and token counts:\n",
      "       entity_1_length  entity_2_length  entity_1_tokens  entity_2_tokens\n",
      "count     70428.000000     70428.000000     70428.000000     70428.000000\n",
      "mean         21.925669        21.868433         3.279378         3.275544\n",
      "std           9.557876         9.542120         1.203934         1.206749\n",
      "min           2.000000         2.000000         1.000000         1.000000\n",
      "25%          16.000000        15.000000         3.000000         3.000000\n",
      "50%          21.000000        21.000000         3.000000         3.000000\n",
      "75%          27.000000        27.000000         4.000000         4.000000\n",
      "max         131.000000       138.000000        17.000000        17.000000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Preprocessing function to clean the text - lower text, remove extra spaces and special chars\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['entity_1'] = df['entity_1'].apply(preprocess_text)\n",
    "df['entity_2'] = df['entity_2'].apply(preprocess_text)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"Missing values in each column:\\n{missing_values}\\n\", )\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\\n\")\n",
    "\n",
    "# Analyze the distribution of the binary tag\n",
    "tag_distribution = df['tag'].value_counts(normalize=True)\n",
    "print(\"Distribution of binary tag:\\n\", tag_distribution)\n",
    "\n",
    "# Look at basic statistics\n",
    "df['entity_1_length'] = df['entity_1'].apply(len)\n",
    "df['entity_2_length'] = df['entity_2'].apply(len)\n",
    "df['entity_1_tokens'] = df['entity_1'].apply(lambda x: len(x.split()))\n",
    "df['entity_2_tokens'] = df['entity_2'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"Basic statistics for entity lengths and token counts:\")\n",
    "print(df[['entity_1_length', 'entity_2_length', 'entity_1_tokens', 'entity_2_tokens']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac3dc2-6e29-4192-8bca-0d43b7ba6721",
   "metadata": {},
   "source": [
    "✅ No missing data\n",
    "\n",
    "✅ No duplicate data\n",
    "\n",
    "⚠️ Class imbalance! 60% non matched entities, 40% matched\n",
    "\n",
    "✅ Entities 1 and 2 seem similar in terms of descriptive statistics regarding length (10-30 chars), token size (2-5)\n",
    "\n",
    "\n",
    "## Model Selection and Evaluation\n",
    "\n",
    "The pipeline works like this:\n",
    "\n",
    "1. Preprocessing: First, we clean the text by lowercasing and removing extra spaces or special characters — just basic stuff to make sure the model isn't confused by small inconsistencies.\n",
    "\n",
    "2. TF-IDF + Cosine Similarity: We turn the company names into character-level n-gram vectors using a basic TF-IDF. These numerical vectors help capture typos, abbreviations, or word order differences while retaining the semantic meaning of the original entity. Then, we calculate cosine similarity between the two name vectors — a common way to measure how close two vectors are based on the angle between them.\n",
    "\n",
    "3. Logistic Regression: Finally, the similarity score goes into a logistic regression model, which learns how to map that score to a binary prediction. The output is a probability score between 0 and 1, which we can use to make predictions.\n",
    " \n",
    "This model setup is good because it's best to start simple when building something from scratch. This setup is fast, has explainable confidence intervals, and should perform well enough — if not, we can always upgrade to a more complex but robust method later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59dab3fa-8b46-42d1-9436-eab72af71203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: ROC-AUC measures how well the model distinguishes between classes. A score of 1 indicates perfect classification.\n",
      "Validation ROC-AUC: 0.999991\n",
      "\n",
      "Explanation: Precision measures the proportion of positive predictions that are correct. Of all the predicted positives, how many were actually positive?\n",
      "Validation Precision: 0.999302\n",
      "\n",
      "Explanation: Recall measures the proportion of actual positives that are correctly identified. Of all the actual positives, how many did we correctly identify?\n",
      "Validation Recall: 0.995828\n",
      "\n",
      "Explanation: The F1-Score is the mean of precision and recall. It is a good balance metric, especially when dealing with imbalanced classes.\n",
      "Validation F1-Score: 0.997562\n",
      "\n",
      "Cross-validation ROC-AUC scores: [0.99999316 0.99998737 0.99999838 0.99998551 0.99999751]\n",
      "Mean CV ROC-AUC: 0.999992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_1</th>\n",
       "      <th>entity_2</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>moai electronics</td>\n",
       "      <td>moai electronics corp</td>\n",
       "      <td>0.999874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69312</th>\n",
       "      <td>unimatec chemicals europe</td>\n",
       "      <td>shanghai twinstars luggage</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28313</th>\n",
       "      <td>knifecenter</td>\n",
       "      <td>dong hyung tem</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td>baader schaltanlagen u leiterplatten gmbh co kg</td>\n",
       "      <td>baader schaltanlagen u leiterplatten gmbh co kg</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67660</th>\n",
       "      <td>rotor doo zemun</td>\n",
       "      <td>akapolco international</td>\n",
       "      <td>0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57669</th>\n",
       "      <td>energiopts spol s</td>\n",
       "      <td>energiopts spol s ro</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>hudikhus ab</td>\n",
       "      <td>hudikhus ab</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40337</th>\n",
       "      <td>derwent shipping logistics ltd</td>\n",
       "      <td>derwent shipping logistics ltd</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>motex modetextilservice logistik und management</td>\n",
       "      <td>kuhlman electric corp</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62198</th>\n",
       "      <td>hammer weilrod verwaltungs gmbh</td>\n",
       "      <td>service metals south limited</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14086 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              entity_1  \\\n",
       "12701                                 moai electronics   \n",
       "69312                        unimatec chemicals europe   \n",
       "28313                                      knifecenter   \n",
       "7831   baader schaltanlagen u leiterplatten gmbh co kg   \n",
       "67660                                  rotor doo zemun   \n",
       "...                                                ...   \n",
       "57669                                energiopts spol s   \n",
       "10650                                      hudikhus ab   \n",
       "40337                   derwent shipping logistics ltd   \n",
       "15528  motex modetextilservice logistik und management   \n",
       "62198                  hammer weilrod verwaltungs gmbh   \n",
       "\n",
       "                                              entity_2      tags  \n",
       "12701                            moai electronics corp  0.999874  \n",
       "69312                       shanghai twinstars luggage  0.001052  \n",
       "28313                                   dong hyung tem  0.001057  \n",
       "7831   baader schaltanlagen u leiterplatten gmbh co kg  0.999964  \n",
       "67660                           akapolco international  0.001049  \n",
       "...                                                ...       ...  \n",
       "57669                             energiopts spol s ro  0.999925  \n",
       "10650                                      hudikhus ab  0.999964  \n",
       "40337                   derwent shipping logistics ltd  0.999964  \n",
       "15528                            kuhlman electric corp  0.001317  \n",
       "62198                     service metals south limited  0.001463  \n",
       "\n",
       "[14086 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "class CosineSimilarityTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Custom transformer to compute cosine similarity between entity_1 and entity_2\n",
    "    # inherit from BaseEstimator, TransformerMixin to be later used with sklearn Pipeline structure\n",
    "    def __init__(self, vectorizer=None):\n",
    "        self.vectorizer = vectorizer or TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        all_text = pd.concat([X['entity_1'], X['entity_2']])\n",
    "        self.vectorizer.fit(all_text)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tfidf_1 = self.vectorizer.transform(X['entity_1'])\n",
    "        tfidf_2 = self.vectorizer.transform(X['entity_2'])\n",
    "        cos_sim = cosine_similarity(tfidf_1, tfidf_2).diagonal()\n",
    "        return cos_sim.reshape(-1, 1)\n",
    "\n",
    "# Reserve 20% for test; from the remaining 80%, use 25% for validation (i.e. 60/20/20 split)\n",
    "# use stratify to preserve class balance\n",
    "train_val, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['tag'])\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42, stratify=train_val['tag'])\n",
    "\n",
    "# Define the pipeline: compute cosine similarity and then use simple logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', FunctionTransformer(lambda X: X.map(preprocess_text))),\n",
    "    ('cosine_sim', CosineSimilarityTransformer()),\n",
    "    ('clf', LogisticRegression(solver='saga', n_jobs=-1))\n",
    "])\n",
    "\n",
    "# fit model\n",
    "X_train = train[['entity_1', 'entity_2']]\n",
    "y_train = train['tag']\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate on the validation set\n",
    "X_val = val[['entity_1', 'entity_2']]\n",
    "y_val = val['tag']\n",
    "y_val_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "auc_val = roc_auc_score(y_val, y_val_pred_proba)\n",
    "precision_val = precision_score(y_val, y_val_pred)\n",
    "recall_val = recall_score(y_val, y_val_pred)\n",
    "f1_val = f1_score(y_val, y_val_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Explanation: ROC-AUC measures how well the model distinguishes between classes. A score of 1 indicates perfect classification.\")\n",
    "print(\"Validation ROC-AUC: {:.6f}\\n\".format(auc_val))\n",
    "\n",
    "print(\"Explanation: Precision measures the proportion of positive predictions that are correct. Of all the predicted positives, how many were actually positive?\")\n",
    "print(\"Validation Precision: {:.6f}\\n\".format(precision_val))\n",
    "\n",
    "print(\"Explanation: Recall measures the proportion of actual positives that are correctly identified. Of all the actual positives, how many did we correctly identify?\")\n",
    "print(\"Validation Recall: {:.6f}\\n\".format(recall_val))\n",
    "\n",
    "print(\"Explanation: The F1-Score is the mean of precision and recall. It is a good balance metric, especially when dealing with imbalanced classes.\")\n",
    "print(\"Validation F1-Score: {:.6f}\\n\".format(f1_val))\n",
    "\n",
    "# Cross-validation on training set using StratifiedKFold (5 folds)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "print(\"Cross-validation ROC-AUC scores:\", cv_scores)\n",
    "print(\"Mean CV ROC-AUC: {:.6f}\".format(np.mean(cv_scores)))\n",
    "\n",
    "# Peek at the predictions\n",
    "predictions = X_val.copy()\n",
    "predictions[\"tags\"] = y_val_pred_proba\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e45c5fe-9198-4ed8-aabf-ca53e8bbefcf",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics Interpretation\n",
    "\n",
    "### ROC-AUC\n",
    "- **Validation ROC-AUC: `0.999991`**\n",
    "  - This score indicates that the model has strong ability to distinguish between the positive and negative classes. A ROC-AUC score close to 1 suggests that the model is highly effective in classifying the entities correctly, with very few false positives and false negatives.\n",
    "\n",
    "### Precision\n",
    "- **Validation Precision: `0.999302`**\n",
    "  - The precision score indicates that 99.93% of the predictions made by the model as positive are indeed correct. Good in applications where false positives can lead to significant issues.\n",
    "\n",
    "### Recall\n",
    "- **Validation Recall: `0.995828`**\n",
    "  - The recall score shows that the model correctly identifies 99.58% of the actual positive cases. In scenarios where identifying all true matches is critical, this score is quite good.\n",
    "\n",
    "### F1-Score\n",
    "- **Validation F1-Score: `0.997562`**\n",
    "  - The F1-Score, which balances precision and recall, is 99.76%. This indicates that the model maintains a good balance between precision and recall, making it a reliable choice for this task. The high F1-Score suggests that the model performs well even in the presence of class imbalance.\n",
    "\n",
    "### Cross-Validation\n",
    "- **Cross-validation ROC-AUC scores: `[0.99999316, 0.99998737, 0.99999838, 0.99998551, 0.99999751]`**\n",
    "  - The cross-validation scores are consistently high, indicating that the model's performance is stable across different subsets of the data.\n",
    " \n",
    "Its important to note however, that we trained on a subset of the data due to resource limitations (running out of RAM locally). We don't necessarily appear to be overfitting yet, but training on a heavier duty machine with more data would be the logical next step before building for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
